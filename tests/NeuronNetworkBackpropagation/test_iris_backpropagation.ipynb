{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris dataset backpropagation\n",
    "By Gerrit van de Bunt, 1756708, 2020-2021\\\n",
    "In this short notebook we will analyse the iris dataset and, based on this analysis, configure a Neural Network using our own code to train upon and classify the entries in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0\n",
    "Import the necessary tools.\\\n",
    "**Note: Due to jupyter notebook importing issues, we will be using a couple of cells to define all the code in our notebook, which drastically increases it's size.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation classes. The idea is as follows;\n",
    "# The classes should have attributes, but should ultimately be callable to be used in the Perceptrons, in order\n",
    "# to return an output.\n",
    "\n",
    "# To this end, make sure that implemented classes have an activate() function that only takes a int or float input\n",
    "# and outputs a int or float.\n",
    "\n",
    "from typing import Union\n",
    "import math\n",
    "\n",
    "class Step:\n",
    "    \"\"\"Step-based activation. If the sum of the input is above the treshold, the output is 1. Otherwise,\n",
    "    the output is 0.\"\"\"\n",
    "    def __init__(self, treshold: Union[int, float] = 0):\n",
    "        self.treshold = treshold\n",
    "\n",
    "    def activate(self, input: Union[int, float]):\n",
    "        if input >= self.treshold:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "class Sigmoid:\n",
    "    \"\"\"Sigmoid-based activation. The output is defined by the sigmoid function.\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Creates the object.\"\"\"\n",
    "\n",
    "    def activate(self, input: Union[int, float]):\n",
    "        return 1 / (1 + (math.e ** -input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neuron class. Takes a list of inputs, applies a list of weights to them, adds a bias,\n",
    "# then applies the sum of that to the activation function and returns an output.\n",
    "\n",
    "from typing import List, Union\n",
    "\n",
    "class Neuron:\n",
    "    \"\"\"Neuron class. To initialise, takes a list of weights, an activation function (normally Sigmoid().activate()), and a bias (optional).\n",
    "    Once initialised, can be activated by giving a list of inputs (with equal elements to the amount of weights)\"\"\"\n",
    "    def __init__(self, weights: List[Union[int, float]], activation: callable, ID=0, bias: Union[int,float] = 0.0):\n",
    "        \"\"\"Initialises the neuron.\"\"\"\n",
    "        # FUNCTIONAL VARIABLES (Private)\n",
    "        self.__weights = weights\n",
    "        self.__activation = activation\n",
    "        self.__bias = bias\n",
    "\n",
    "        self.__newweights = []\n",
    "        self.__newbias = 0\n",
    "\n",
    "        # LOGGING VARIABLES (Public)\n",
    "        self.ID = ID  # Identifier for Perceptron, for debugging.\n",
    "\n",
    "        self.error = 0  # Error calculated by the error methods.\n",
    "\n",
    "        self.hasrun = False  # Whether the neuron has been activated or not.\n",
    "        self.input = []  # Inputs of previous activations\n",
    "        self.output = []  # Output of previous activations\n",
    "\n",
    "    def getweights(self) -> List[Union[int, float]]:\n",
    "        \"\"\"Returns the current weights.\"\"\"\n",
    "        return self.__weights\n",
    "\n",
    "    def setweights(self,weights: List[Union[int, float]]):\n",
    "        \"\"\"Changes the weights on this neuron by using a supplied weightslist.\n",
    "        For proper use in the PerceptronLayer class, the input has to have the same\n",
    "        amount of elements as the original weights list.\"\"\"\n",
    "        if not len(weights) == len(self.getweights()):\n",
    "            raise Exception(\"Amount of supplied weights does not equal the amount of current weights @ Perceptron {}\".format(self.ID))\n",
    "        self.__weights = weights\n",
    "\n",
    "    def getactivation(self) -> callable:\n",
    "        \"\"\"Returns the current activation function.\"\"\"\n",
    "        return self.__activation\n",
    "\n",
    "    def setactivation(self, func: callable):\n",
    "        \"\"\"Changes the activation function on this neuron.\"\"\"\n",
    "        self.__activation = func\n",
    "\n",
    "    def getbias(self) -> Union[int, float]:\n",
    "        \"\"\"Returns the current bias for this neuron.\"\"\"\n",
    "        return self.__bias\n",
    "\n",
    "    def setbias(self, b: Union[int, float]):\n",
    "        \"\"\"Changes the current bias on this neuron.\"\"\"\n",
    "        self.__bias = b\n",
    "\n",
    "    def activate(self,inputs: List[Union[int, float]]) -> Union[int,float]:\n",
    "        \"\"\"Activates the Perceptron by supplying inputs.\"\"\"\n",
    "        # RESETS\n",
    "        self.hasrun = False\n",
    "        # PRECHECKS\n",
    "        if not len(inputs) == len(self.__weights):\n",
    "            raise Exception(\"Amount of inputs is not equal to the amount of weights @ Perceptron {}\".format(self.ID))\n",
    "        # PROCESSING\n",
    "        weightedlist = []  # List with processed inputs (input*weight)\n",
    "\n",
    "        for indx in range(len(self.__weights)):\n",
    "            weightedlist.append(self.__weights[indx] * inputs[indx])\n",
    "\n",
    "        output = self.__activation(sum(weightedlist) + self.__bias)\n",
    "        # Consider evaluation succesful past this point; get logging variables.\n",
    "        self.hasrun = True\n",
    "        self.input.append(inputs)\n",
    "        self.output.append(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def erroroutput(self, target: Union[int,float], learningrate: Union[int,float]):\n",
    "        \"\"\"Calculates the error of an output neuron.\"\"\"\n",
    "        if not self.hasrun:\n",
    "            raise Exception(\"Run the Neuron first! @ Neuron {}\".format(self.ID))\n",
    "        gradients = []\n",
    "        deltaweights = []\n",
    "        deltabias = 0\n",
    "        newweights = []\n",
    "        newbias = 0\n",
    "        # Bepaal de error\n",
    "        output = self.output[-1]\n",
    "        error = output * (1-output) * -(target-output)\n",
    "        for inp in self.input[-1]:\n",
    "            gradients.append(inp * error)  # De output van een voorgaande node is gelijk aan de input op deze node op de relevante index\n",
    "        for grad in gradients:\n",
    "            deltaweights.append(learningrate * grad)\n",
    "        deltabias = learningrate * error\n",
    "\n",
    "        self.error = error\n",
    "        self.__newweights = [self.__weights[i] - deltaweights[i] for i in range(len(self.getweights()))]\n",
    "        self.__newbias = self.getbias() - deltabias\n",
    "\n",
    "    def errorhidden(self, connections: List[Union[int,float]], errors: List[Union[int,float]], learningrate: Union[int,float]):\n",
    "        \"\"\"Calculates the error of a hidden layer neuron\"\"\"\n",
    "        if not self.hasrun:\n",
    "            raise Exception(\"Run the Neuron first! @ Neuron {}\".format(self.ID))\n",
    "        if len(connections) != len(errors):\n",
    "            raise Exception(\"Amount of connections from this neuron should equal the amount of errors from neurons @ Neuron {}\".format(self.ID))\n",
    "        gradients = []\n",
    "        deltaweights = []\n",
    "        deltabias = 0\n",
    "        newweights = []\n",
    "        newbias = 0\n",
    "        sum = 0  # Sum of (Wi,j * Delta(j))\n",
    "        # Bepaal de error\n",
    "        output = self.output[-1]\n",
    "        for i in range(len(connections)):  # Bepaal eerst de som van de vermenigvuldigingen tussen de verbindingen en de errors.\n",
    "            sum += connections[i] * errors[i]\n",
    "        error = output * (1-output) * sum  # Bepaal dan uiteindelijk de error.\n",
    "        for inp in self.input[-1]:\n",
    "            gradients.append(inp * error)  # De output van een voorgaande node is gelijk aan de input op deze node op de relevante index\n",
    "        for grad in gradients:\n",
    "            deltaweights.append(learningrate * grad)\n",
    "        deltabias = learningrate * error\n",
    "\n",
    "        self.error = error\n",
    "        self.__newweights = [self.__weights[i] - deltaweights[i] for i in range(len(self.getweights()))]\n",
    "        self.__newbias = self.getbias() - deltabias\n",
    "\n",
    "    def update(self):\n",
    "        \"\"\"Updates the weights and bias using stored new weights and bias.\"\"\"\n",
    "        self.setbias(self.__newbias)\n",
    "        self.setweights(self.__newweights)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"Returns a string representing the object and it's variables.\"\"\"\n",
    "        output = \"\"\n",
    "        output += \"NEURON ID: {}\\n\\n\".format(self.ID)\n",
    "\n",
    "        output += \"WEIGHTS: {}\\n\".format(self.getweights())\n",
    "        output += \"ACTIVATION: {}\\n\".format(self.getactivation().__name__)\n",
    "        output += \"BIAS: {}\\n\".format(self.getbias())\n",
    "\n",
    "        if self.hasrun:\n",
    "            output += \"SUCCESFUL ACTIVATION \\n\\n\".format(self.hasrun)\n",
    "            output += \"INPUT: {}\\n\".format(self.input)\n",
    "            output += \"OUTPUT: {}\\n\".format(self.output)\n",
    "        else:\n",
    "            output += \"ACTIVATION PENDING/FAILED\\n\"\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeuronLayer defines the layers in the network. This is where the Neuron Class is used.\n",
    "\n",
    "# By default, all the Layers must be connected, so each neuron in the network must have equally as many\n",
    "# weights as one another, and the amount of weights on all perceptrons should equal the amount of connections from one layer to the\n",
    "# other on a per-neuron basis.\n",
    "\n",
    "from typing import List, Union, Any\n",
    "\n",
    "class NeuronLayer:\n",
    "    \"\"\"Defines a layer in a NeuronNetwork.\"\"\"\n",
    "    def __init__(self, neurons: List[Neuron], ID: Any = 0):\n",
    "        self.neurons = neurons\n",
    "        self.outputs = []\n",
    "\n",
    "    def activate(self, inputlist: List[Union[int, float]]):\n",
    "        \"\"\"Runs the inputlist through all perceptrons of the network and saves the output.\"\"\"\n",
    "        self.outputs = []\n",
    "        for i in self.neurons:\n",
    "            i.activate(inputlist)\n",
    "            self.outputs.append(i.output[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The NeuronNetwork houses **all** the layers of the network.\n",
    "\n",
    "from typing import List, Union, Any  # Onschuldige library die alleen beter laat zien wat voor soorten inputs er verwacht worden.\n",
    "\n",
    "class NeuronNetwork:\n",
    "    \"\"\"Defines the neuron network; wraps all the given layers into this network.\"\"\"\n",
    "    def __init__(self, layers: List[NeuronLayer], learningrate: Union[int,float] = 0.3, ID: Any = 0,):\n",
    "        \"\"\"Initialises a neuron network. Handles the connections between the layers.\"\"\"\n",
    "        self.hiddenlayers = layers\n",
    "        self.learningrate = learningrate\n",
    "        self.input = []\n",
    "        self.output = []\n",
    "\n",
    "        self.ID = ID\n",
    "        self.hasrun = False\n",
    "\n",
    "\n",
    "\n",
    "    def feed_forward(self, inputs: List[Union[int,float]]) -> List[Union[int,float]]:\n",
    "        \"\"\"Starts the network, feeds in the inputs, runs it through all the layers and returns the output\n",
    "        of the final layer.\"\"\"\n",
    "        self.hasrun = False\n",
    "        totalinputs = inputs.copy()  # Keep both lists unlinked; original list will be saved for debugging.\n",
    "        for layer in self.hiddenlayers:\n",
    "            layer.activate(totalinputs)\n",
    "            totalinputs = layer.outputs.copy()  # Same deal here\n",
    "\n",
    "        self.input = inputs\n",
    "        self.output = totalinputs\n",
    "        self.hasrun = True\n",
    "\n",
    "        return totalinputs\n",
    "\n",
    "    def backpropagation(self, actualoutput):\n",
    "        outputlayer = self.hiddenlayers[-1]\n",
    "\n",
    "        if len(outputlayer.neurons) != len(actualoutput):\n",
    "            raise Exception(\"Not enough outputs for each neuron in the output layer @ NeuronNetwork {}\".format(self.ID))\n",
    "\n",
    "        for i in range(len(outputlayer.neurons)):\n",
    "            outputlayer.neurons[i].erroroutput(actualoutput[i],self.learningrate)\n",
    "        # Nu komt het lastige gedeelte...\n",
    "        # Amount of connections is equal to the amount of neurons in the previous layer!!\n",
    "        # Currentlayer (i) : Target to call .errorhidden() on. Also get index in the neuron list.\n",
    "        # Nextlayer (i+1) : Target to get weights from. Use index acquired in the previous layer.\n",
    "        for lindx in range(len(self.hiddenlayers)-2,-1,-1):\n",
    "            for i in range(len(self.hiddenlayers[lindx].neurons)):\n",
    "                weights = []\n",
    "                errors = []\n",
    "                for neuron in self.hiddenlayers[lindx+1].neurons:\n",
    "                    weights.append(neuron.getweights()[i])  # Gets the weights that this neuron connects to on neurons in the next layer\n",
    "                    errors.append(neuron.error)  # Gets the error at the same time.\n",
    "                self.hiddenlayers[lindx].neurons[i].errorhidden(weights,errors,self.learningrate)\n",
    "\n",
    "    def update(self):\n",
    "        \"\"\"Updates all the weights and biases in the network immediately, given\n",
    "        that all neurons have had their \"\"\"\n",
    "        for layer in self.hiddenlayers:\n",
    "            for neuron in layer.neurons:\n",
    "                neuron.update()\n",
    "\n",
    "    def train(self, inputs: List[List[int]], actualoutputs: List[List[int]], epochs: int = 40, errortreshold: float = 0.1) -> None:\n",
    "        error = errortreshold+1\n",
    "        while epochs > 0 and error >= errortreshold:\n",
    "            for i in range(len(inputs)):\n",
    "                self.feed_forward(inputs[i])\n",
    "                self.backpropagation(actualoutputs[i])\n",
    "                self.update()\n",
    "                error = self.error(inputs,actualoutputs)  # MSE\n",
    "                if error < errortreshold:\n",
    "                    break\n",
    "            epochs -= 1\n",
    "\n",
    "    def error(self, inputs: List[List[Union[int,float]]], actualoutputs: List[List[Union[int,float]]]) -> float:\n",
    "        \"\"\"Calculates the MSE of this network's output layer over a training set.\"\"\"\n",
    "        outputs = []\n",
    "        sumoutputs = []\n",
    "        for i in range(len(inputs)):\n",
    "            self.feed_forward(inputs[i])\n",
    "            outputs.append(self.output)\n",
    "            # Verwijder ook hier weer de resulterende inputs en outputs, die willen we niet; error moet gezien\n",
    "            # worden als een functie zonder side-effects.\n",
    "            for neuronlayer in self.hiddenlayers:\n",
    "                for neuron in neuronlayer.neurons:\n",
    "                    del neuron.output[-1]\n",
    "                    del neuron.input[-1]\n",
    "\n",
    "        for i1 in range(len(outputs)):\n",
    "            for i2 in range(len(outputs[i1])):\n",
    "                sumoutputs.append((actualoutputs[i1][i2] - outputs[i1][i2])**2)\n",
    "\n",
    "        return sum(sumoutputs) / len(outputs)\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Tries to print out the network in a readable manner.\n",
    "        Additional information is available once the network has been run once.\"\"\"\n",
    "        output = \"\"\n",
    "        output += \"NEURONNETWORK ID: {}\\n\".format(self.ID)\n",
    "        if self.hasrun:\n",
    "            output += \"INPUT: {}\\nV\\n\".format(self.input)\n",
    "        for layer in self.hiddenlayers:\n",
    "            for i in layer.neurons:\n",
    "                output += \"[{} + {}]\\n\".format([round(x,4) for x in i.getweights()],round(i.getbias(),4))\n",
    "            if self.hasrun:\n",
    "                output += \"OUTPUT: {}\\n\".format(layer.outputs)\n",
    "            output += \"V\\n\"\n",
    "        if self.hasrun:\n",
    "            output += \"FINAL OUTPUT: {}\\n\".format(self.output)\n",
    "        else:\n",
    "            output += \"ACTIVATION PENDING\\n\"\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stap 1 - Data collection\n",
    "Importeer de dataset en kijk naar de eerste gegevens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_iris(as_frame=True)\n",
    "frame = data[\"frame\"]\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)      target  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.199333    1.000000  \n",
       "std            0.762238    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stap 2 - Data analysis\n",
    "We willen kijken of er een correlatie gevonden kan worden tussen de targets en de verschillende attributen.\n",
    "Hiervoor gebruiken we een pearson correlatie matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ba15a48>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbMAAAFKCAYAAACXcLFWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3wUVdfA8d8hoPSEhJCQUAKhqaBBEAREmmBAKQoqPqjwiiKoWEFBBSsI9gdBEWzYRSwgIlgBQUWKSBEQEJRQEnpLgCR73j92CJtkIRuyyWZ5zpfPftiZuXPnTCbZM/fO3RlRVYwxxphgViLQARhjjDEFZcnMGGNM0LNkZowxJuhZMjPGGBP0LJkZY4wJepbMjDHGBD1LZsYYY/xKRN4UkRQRWXWS5SIi40Rkg4isEJELC7pNS2bGGGP87W0g8RTLOwN1ndcA4NWCbtCSmTHGGL9S1fnAnlMU6Q68o26/AmEiUrUg27RkZowxpqjFAls8ppOceaetZIHCMYUmfdffZ9x9xq5vck+gQygU703rG+gQ/E737wx0CIUj9VCgIygUZboNkYLW4etnzlmR8bfh7ho8bpKqTsrn5rzFW6DPPEtmxhhjwJXpUzEnceU3eeWUBFT3mK4GbCtIhdbNaIwxBtTl28s/ZgA3OaMaLwb2q+r2glRoLTNjjDHg8luiQkQ+BNoClUUkCXgUKAWgqhOBWUAXYAOQCvxfQbdpycwYYwyameG/ulSvz2O5Anf4bYNYMjPGGAP+7EIMCEtmxhhjfB4AUlxZMjPGGGMtM2OMMWcAPw4ACQRLZsYYY/w6ACQQLJkZY4yxbkZjjDFnABsAYowxJuhZy8wYY0zQswEgxhhjgp61zIwxxgQ7zUwPdAgFYsnMGGOMtcxM8Hpk9AvMX/gb4ZXC+OK9iYEOJ19ufuxWGrdryrG0o4wf8hKbVv2dq0xi3yu44uZuVI2ryv8l9OHg3oMAtO7Rhh4DewJwJDWNSQ+/yj9rNhdl+Lks/OMvxr47E5fLxVVtL6J/tzbZlh9MPcJDr05lx+59ZGS66NulNT3aNGHztp08MP6jrHJJKXu4vddl3JDYqqh3wauFqzfzzLS57v1q1ZCbOzXLtvxg2lEefvtrduw9SEami5sua0qPFuexY+9BHpkym90HUhGBnpc0ok+7CwO0F9ktXLuFZ2b8gsulXNWsPje3T8i2/O25fzBr2QYAMl3KppR9/PjYDYSWLc2781fy+W9rEYS6VcN5/NpLObtUMfkYDvJrZgF9npmItBWRmb7O98P2eojIuR7Tc0WkqQ/rVfVHPCISKSKzC1qPv/To0pGJLzwV6DDyrXG7JlStFcPgNrcxcfgEBjw1yGu5dUvW8ESfEaRsSc42P2VLMiOvHc79iXcxbdzHDHzarzfvzrdMl4vRU2bwygP9+PyZe5j96x9s3Jo95o+//ZXasVX4ZPRdvPHwLTz/wSzSMzKIi4lk6ujBTB09mA+fuoPSZ5eifdNzT7KlopXpcvH01B+YcEcPPhvRl9lL1rFx++5sZT6e9we1q0Yw9aEbef2ea3jhs3mkZ2QSUkK4/+pL+XxkX94dej0fz/8j17qBkOly8fTnC5nQP5HPhvRi9vKNbEzem61Mv7YXMPW+nky9ryd3dbmIJrWjCS1bmuT9h/lwwSo+uPsqPh3Si0yXi9nLc5+EBUzRPs/M7/7XHs7ZAzidv/T7gMkF3biq7gS2i0ixOG1umtCI0IoVAh1Gvl3UsTlzP/0RgPW/r6NsxXKEVamUq9ym1X+zMykl1/x1S9dy+MBhAP5ato7wqpULN+A8rNqYRPWoCKpVCadUyZIkXnw+c5euyVZGBFLTjqKqpB45Rmi5MoSUyP7nu2j1RqpXCSemcu6fRSCs2ryD6pFhVKscRqmSIVzepD5zV2zMVkYEDh85hqqSdjSd0LKlCSlRgsjQ8pxTIwqAcqXPonZUOCn7DgViN7JZ9e9OqleuSLWIiu59Sohn7up/Tlr+6983kti4TtZ0pks5mp5BRqaLI+kZRFYsWxRh+8aV6durmDplMhORciLylYj8ISKrROQ6Z34TEZknIktFZI6IVHXmzxWRl0TkZ6d8M2d+M2fe787/9X0N0InhTRFZ7Kzf3ZnfT0Q+E5HZIrJeRJ7xWKe/iPzlxDNZRMaLSEugG/CsiCwXkXin+DUi8ptTvvVJwugJzHbqDhGR50RkpYisEJHBzvzNIjJaRH4RkSUicqHzs9koIgM96voC6OPr/pvcIqIj2L1tZ9b0nh27iYiKOK26OvTuyO9zl/ortNOSsnc/0eGhWdNVwkNJ3nsgW5neHVvw97YULrtzDL2Gj+OBG6+kRI5kNvuXFSS2uKBIYvZFyr5DRFc6cbIUFVY+V0Lq3SaBTTv20PGhSfQa9S5Dr2lLiRKSrczW3ftZm7STRnHRRRL3qaQcOEx0WPms6ajQcqTsP+y1bNqxDH5el8RljeKyyt7U5nwSR31Ixyffp3zps2hZv1pRhO2bzAzfXsVUXi2zRGCbql6gqg2B2SJSCngZ6KWqTYA3gVEe65RT1ZbA7c4ygLXAparaGBgJjM5HjA8DP6jqRUA73MmonLMsAbgOaARcJyLVRSQGGAFcDHQEGgCo6s+4H9U9VFUTVPX4KWJJVW0G3IP7aajZiEgtYK+qHnVmDQBqAY1V9XzgfY/iW1S1BfAT8DbQy4njCY8ySwCvSVNEBjiJcMnr73zo20/nf5HknuV+1l/+nNeiEe2v68h7T0/xQ1Cnz1voOXfx55V/0aBmDN+NH8bUUYN5+p0vOZR6JGt5ekYG85atoVPzhoUbbD54OyIi2ffs5z83U79aJN+OHsDHw29gzNQfOZR2NGt56pFjDJk8k6G92lC+zNmFHHHevB4rL7+PAPP//IeEuChCy5YG4EDqUeau3sxXw3vzzYg+pB3L4Kul6wsx2nwK8m7GvK48rgSeE5GxwExV/UlEGgINgW+dX8wQYLvHOh8CqOp8EakoImFABWCKiNTF/TteKh8xdgK6icgQZ7o0UMN5/72q7gcQkT+BmkBlYJ6q7nHmfwLUO0X9nzn/LwXivCyvCuz0mL4MmKiqGc5+7vFYNsP5fyVQXlUPAgdF5IiIhKnqPiAFiPEWiKpOAiYBpO/6O/+fzmewxJu60KF3JwA2rlhPREwk4O6KC4+OYE/KnlOsnVvNBnEMGnsno/o+zqF9B/0dbr5EhYeyY8/+rOmUPfupUqlitjLT5y3j5q6XIiLUiI4gNrISm7bvpFF8dQAW/PEXDeJiiAgtPt3GUWHl2bH3xM82ed8hIkPLZSsz/dc/ublTU/d+VQkjNiKUTcl7aRQXTXpmJve/PpMuFzWgQ0Ldog7fq6jQcuzwaF0m7z9MZMVyXsvOXr6RxMbxWdO/rt9KbHgFwsuXAaBDwziW/5PMFU2Kx76d0QNAVPUvoAnuD+enRWQk7pPG1U7rJkFVG6lqJ8/VclYDPAn86LTuuuJOSL4SoKfH9mqo6vELCkc9ymXiTs4nOU86qeN1HF8/p7Qc8QreTzo963LliM3lUXdpp06TD7PfmcXQLvcwtMs9/PbNItr2bAdA3cb1ST2Yyr6UvXnUcELlmMoMeW04L9/7Its3bSuskH12Xu1Y/t2xi6SUPaRnZDD71xW0ufCcbGWiK4eyaLW7M2H3/oNs3r6LalXCs5Z//csfdC5GXYwA59WM5t+UvWzdtZ/0jEzmLF1Hm0a1s5WpWqkCi9ZtAWD3gcNsTt5DtcqhqCqPv/cttaLDubFDk0CE79V51SP5d9cBtu454N6n5Rtpc26NXOUOph1j6d87aHdezax5VSuVZ8W/KaQdy0BVWbRhG7WrhBVl+Kfmcvn2KqZO2TJzuuz2qOp7InII6AeMASJFpIWq/uJ0O9ZT1dXOatcBP4rIJcB+Vd0vIqHAVmd5v3zGOAcYLCKDVVVFpLGq/n6K8r8BL4pIJeAg7utdK51lB3G3EvPjL7K32L4BBorIXFXNEJHwHK2zvNQDVuUzhkIx9NExLP59Bfv2HaBDjxu4vf+N9Ox6eaDDytOyH5ZwYbsmjJ//GkfTjvLKkHFZyx56eySvPjCevSl76NLvSroPvJqwyEo8P2ccy35cysQHx9Pr7t5UqFSBW550X8p0ZWbyYNf7A7U7lAwJYXjfbgx65i1cLqVHmybUqRbF1O8XAXBth+YM6NGeEa9No+ew/6Io91x3OZUquFsEaUeP8euqDYy4+aqA7YM3JUNKMOza9gya8Bkul9K9xXnUianMJz/9AcA1rS/g1s7NGfnuHHqNegdVuKdHayqVL8PvG7Yy87c11I2pzLWj3wNgcLdWtG5YK5C75N6nHi0ZNPlr9z41q0+d6HA++eVPAK5p4R5f9sOqzbSoF0uZs050QjWqUYXLGtXm+pc+I6RECRrERtDz4nO8bicQVIvv4A5fyKmuNYjI5cCzuFsW6cAgVV0iIgnAOCAUd0J8SVUni8hc4BegDVARuFlVfxORFsAU3N11PwA3qmqciLQFhqjqlTm2mzVfRMoALwEtcbeKNjvz+wFNVfVOZ52ZwHOqOldEBgBDgG24+6L2qOrDzijCybhbTb2AN5ztLBGRysASVY3z8nP4HrhNVTeISEngGdzXE9OByao6XkQ2O/Hs8hKb57IhwFFVfflUB+ZM7Ga8vsk9gQ6hULw3rW+gQ/A73b8z70LBKDXwIyILQ5luQ/LbI5VL2tw3ffrMKdP25gJvqzCcMpnluzJ3Mhuiqkv8VunpxVFeVQ85iedz4E1V/bwA9V0FNFHVR/wQ23ygu6qesl/MklnwsGQWRCyZnVTa95N8S2YdBhTLZHamfs/sMRFZjrs7bxPu4fCnzUmEmwsalIhEAi/klciMMabI+XE0o4gkisg6EdkgIsO8LA8VkS+dr32tFpH/K2j4fr2Piqq29Wd9p0tVh+RdKt91vu6HOnZSwMRqjDGFwk+DO0QkBJiA+6tRScBiEZmhqn96FLsD+FNVuzon+etE5H1VPXa62z1TW2bGGGPyw38ts2bABlX920lOHwHdc24NqCDu73eVB/YABfpGtiUzY4wxPg/N97y5g/MakKOmWGCLx3SSM8/TeOAc3IP0VgJ3qxbsG9nF5HbNxhhjAsrHbkbPmzuchLcBIjkHl1wOLAfaA/G4b8Lxk6oeyLWmj6xlZowxxp/3ZkwCqntMV8PdAvP0f8Bn6rYB90C9BgUJ35KZMcYYf14zWwzUFZFaInIW0JsTt/o77l+gA4CIRAH1gQI9D8e6GY0xxvhtNKNzZ6Q7cd+9KQT393xXH396iKpOxH2Lw7dFZCXubskHVXVXQbZrycwYY4xf74ivqrOAWTnmTfR4vw33TeT9xpKZMcaYYn0TYV9YMjPGGAOZwX2jYUtmxhhjrGVmjDHmDGDJzBhjTNDz4wCQQLBkZowxxlpmxhhjzgB+fLZlIFgyK6bOxAdZfrj0pUCHUCjKxLQOdAh+V/HssoEOoVAcOJoa6BAKRcYxPzz1KqNAN60POEtmxhhj7JqZMcaY4Kcu62Y0xhgT7GwAiDHGmKBn3YzGGGOCnnUzGmOMCXo2mtEYY0zQs++ZGWOMCXo2AMQYY0zQs2tmxhhjgp6NZjTGGBPsNMMezmmMMSbYWTejMcaYoBfk3YwlAh2AMcaYYsClvr18ICKJIrJORDaIyLCTlGkrIstFZLWIzCto+NYyM8YY47eh+SISAkwAOgJJwGIRmaGqf3qUCQNeARJV9V8RqVLQ7VrLzBhjjD9bZs2ADar6t6oeAz4Cuuco8x/gM1X9F0BVUwoaviWzM9zNj93Ky/Ne4/nZ46jVsLbXMol9r+Dlea8x7Z8ZVKhUIWt+6x5teH72OJ6fPY5Rn42l5jlxRRT16Xtk9AtcekVvetwwMNCh5NuLLzzB2j8XsGzptzROaHjKsi+9+CT79vyVNd21ayeWLf2WJYu/4ddfZtGq5UWFHa7Pnn5mBEuWf8dPv3zJ+Rec67XMuAmjmf/zDH765UvefvdlypVzPxx08N23MG/hDOYtnMHCRV+xc99awiqFFmX4Xp2Rxyoz06eXiAwQkSUerwE5aooFtnhMJznzPNUDKonIXBFZKiI3FTT8YpfMnH7UmaexXoyITDvJsrki0tR5/5DH/DgRWeVj/ff44wcuIneKyP8VtB5fNG7XhKq1Yhjc5jYmDp/AgKcGeS23bskanugzgpQtydnmp2xJZuS1w7k/8S6mjfuYgU/fURRhF0iPLh2Z+MJTgQ4j3zontqdunVo0OPcSBg16kAnjnz5p2SYXnk9YWPYP9B9+WMCFTTrS9KJO3Drgfl577bnCDtknl3VqQ3x8TZomXMa9d43g+Ref8Fru4WGjubRlN1q36EpS0jZuue0GAF7+7+u0adWNNq268cRjz7NwwW/s27u/KHchlzP1WKnL5dtLdZKqNvV4TcpRlXirPsd0SaAJcAVwOTBCROoVJP5il8xOl6puU9VePhR9KO8i2YlISeBm4IN8B5bbm8BdfqgnTxd1bM7cT38EYP3v6yhbsRxhVSrlKrdp9d/sTMrdyl+3dC2HDxwG4K9l6wivWrlwA/aDpgmNCK1YIe+CxUzXrpfz7vvuc7FFvy0jNCyU6OjclxFKlCjB2DEjGDY8e8I+fDg16325smXRYnKfvS5XXMZHH34BwJLFy6kYVoGoqMhc5Q4ePJT1vnTp0l5vE9iz15V8Ni3f57l+d6YeKz92MyYB1T2mqwHbvJSZraqHVXUXMB+4oCDh5zuZiUg5EflKRP4QkVUicp0zv4mIzHOajHNEpKozf66IvCQiPzvlmznzmznzfnf+r5/HdmeJyPnO+99FZKTz/kkRucWzlSUiZUTkIxFZISIfA2Wc+WOAMs4ImvedqkNEZLIzouYbESnjZfPtgWWqmuHUU0dEvnN+BstEJN5pUc4Tkaki8peIjBGRPiLym4isFJF4AFVNBTYf/zkUpojoCHZv25k1vWfHbiKiIk6rrg69O/L73KX+Cs3kEBsTTdKWE3/vW5O2ExsTnavcHbf/H1/O/IYdO3KffHTvnsiqlfOYMX0Kt956f6HG66uqMVFs3bo9a3rb1h1UjYnyWnb8q2NYu/EX6tarzeSJ72RbVqZMaTpc1poZ0+cUary+OFOPlR+T2WKgrojUEpGzgN7AjBxlpgOtRaSkiJQFmgNrChL+6bTMEoFtqnqBqjYEZotIKeBloJeqNsHd+hjlsU45VW0J3O4sA1gLXKqqjYGRwOg8tjsf985XBDKAVs78S4CfcpQdBKSq6vlOHE0AVHUYkKaqCaraxylbF5igqucB+4CeXrbdCvD8JH/fWecCoCVw/K/1AuBuoBFwI1BPVZsBrwODPdZfArTOY38Lzktj/3TOAs9r0Yj213Xkvaen+CEo441I7oOV81hVrRpFr55XMn7Cm7nKAkyfPpuGjdrQs1d/Hn9saKHEmV++7Ndxdw4axrl1W/HXuo1c1fOKbMsSO7dn0aJlAe9ihDP3WKEu3155VeM+6b8TmIM7QU1V1dUiMlBEBjpl1gCzgRXAb8DrqurTJZ+TOZ2h+SuB50RkLDBTVX8SkYZAQ+Bb50CHcOIDHuBDAFWdLyIVnWGZFYApIlIXd39qqTy2+xPu7rlNwFdARyejx6nqOhGJ8yh7KTDO2eYKEVlxino3qepy5/1SIM5Lmao4Zw0iUgGIVdXPnfqPOPMBFqvqdmd6I/CNs/5KoJ1HfSlAg5wbcS6kDgBoHH4+tcvXPEXY3iXe1IUOvTsBsHHFeiJiIo+HTnh0BHtS9uSrvpoN4hg09k5G9X2cQ/sO5jsec3KDBvalf3/3OdWSJcupVj0ma1lstaps2579GmbjhIbEx8exbs1CAMqWLcPaPxfQ4NxLspX7acEiateuSUREJXbv3lvIe5Fb/1v7cFO/6wD4fdkKYmOrZi2LiY1mx/aTD1xzuVx8/uksBt9zCx+892nW/Kt6XcGnnwSui/FMPVbZ+PEOIKo6C5iVY97EHNPPAs/6a5v5bpmp6l+4Wzorgaed7j4BVjstngRVbaSqnTxXy1kN8CTwo9O66wqUzmPTi4GmuFs084HfgVvJ3mLKuQ1fHPV4n4n3BJ/mEZ+3i5ve6nJ5TLty1FvaqTMbzwurp5PIAGa/M4uhXe5haJd7+O2bRbTt6c6hdRvXJ/VgKvtSfP+DqRxTmSGvDefle19k+6acXd6moF6dOIWmF3Wi6UWdmDFjDjf2cV/ybd7sQg7sP5Cre2rW199TrUZj6tS7mDr1LiY1NS3rwzE+Pi6rXOOEhpx1VqmAfTi+Mfn9rEEbX838jt7X9wCg6UUJHNh/kOTknbnWqVW7Rtb7xC7tWP/XxqzpChXL06pVM77+6rvCD/4kztRj5UkzXD69iqt8t8xEJAbYo6rvicghoB8wBogUkRaq+ovT7VhPVVc7q10H/CgilwD7VXW/iIQCW53l/fLarqoeE5EtwLW4E2Ek8Jzzymk+0MfZZkPgfI9l6SJSSlXT87Hba4A6ThwHRCRJRHqo6hcicjbulmh+1AMW5nOdfFv2wxIubNeE8fNf42jaUV4ZMi5r2UNvj+TVB8azN2UPXfpdSfeBVxMWWYnn54xj2Y9LmfjgeHrd3ZsKlSpwy5PuYe6uzEwe7FpM+vdPYuijY1j8+wr27TtAhx43cHv/G+nZ9fJAh5WnWV9/T2Jie9atWUhqWhq33HJf1rIvp7/DgIFD2Z7j7N/T1Vd14YYbepGensGRtCP8p4/3katF7ds5c+nYqQ1L//ietLQ07hx04mYQH0+bzN13Pkxy8k5eee0ZKlQoj4iwauVahtz7aFa5K7t24scfFpCamuv8LyDO1GMV7M8zk/xeQxGRy3E3DV1AOjBIVZeISALurr1Q3EnyJVWdLCJzgV+ANkBF4GZV/U1EWgBTgJ3AD8CNqhonIm2BIap6pZdtPwl0UNWWTlLdCjRR1WVON+NMVW3oDOJ4CzgXWI47Ed3lxDkW6AYsAx4+vo5T/xCgvKo+lmO7NYF3VfVSZ7ou8BpQ2fkZXAPU8Izb2e8hzjbb5li2DOjkjOLxqlfNbsVkiJP/fLj0pUCHUCjKxBT+5c+iVvHssoEOoVAcOJqad6EglHFs66l6jHxy8PbOPn3mVHjl6wJvqzDkO5nlewMeH+qFuqFCJiKfAw+o6voC1tMYuE9VbzxVOUtmwcOSWfCwZHZyBwcm+pbMJs4ulsnsjPmeWREYhnsgSEFVBkb4oR5jjPEbVfXpVVwV+o2GVbVtYW+jKKjqOmCdH+r51g/hGGOMfxXjwR2+sLvmG2OMQe3hnMYYY4KeJTNjjDFBL7h7GS2ZGWOMsW5GY4wxZwJLZsYYY4KdZlgyM8YYE+zsmpkxxphgZ9fMjDHGBD9rmRljjAl2Pjx3s1izZGaMMQbNCHQEBWPJzBhjjHUzGmOMCX7WzWiMMSboWTIzheK9aX0DHYLfnYkPsQRI2/ZToEPwO007GOgQCkf60UBHUGxZMjPGGBP8tFg+QNpn9qRpY4wxuDLEp5cvRCRRRNaJyAYRGXaKcheJSKaI9Cpo/JbMjDHGoC7fXnkRkRBgAtAZOBe4XkTOPUm5scAcf8RvycwYYwyq4tPLB82ADar6t6oeAz4CunspNxj4FEjxR/yWzIwxxvjcMhORASKyxOM1IEdVscAWj+kkZ14WEYkFrgIm+it+GwBijDEGdfl2PUxVJwGTTlHEW0U572L8EvCgqmaK+GfgiSUzY4wxqP9ump8EVPeYrgZsy1GmKfCRk8gqA11EJENVvzjdjVoyM8YYgyvDb1edFgN1RaQWsBXoDfzHs4Cq1jr+XkTeBmYWJJGBJTNjjDH4r2WmqhkicifuUYohwJuqulpEBjrL/XadzJMlM2OMMT5fM/OpLtVZwKwc87wmMVXt549tWjIzxhjj67D7YsuSmTHGGLs3ozHGmOCX6Qrurx1bMjPGGOPXa2aBYMnMGGOMP79nFhCWzIwxxljLzBhjTPBz2WhGU1wt/OMvxr47E5fLxVVtL6J/tzbZlh9MPcJDr05lx+59ZGS66NulNT3aNGHztp08MP6jrHJJKXu4vddl3JDYqqh34aRefOEJOie2JzUtjf797+X35atOWvalF5+kX9/rCAuvB0DXrp14/LGhuFxKRkYG99//KAt/XlxUoZ+WR0a/wPyFvxFeKYwv3iuU75wWigW/LWfsK2+R6XJxdecO3HJ9j2zL9x88xMjnXmXLtmTOPqsUTwwZRN1aNQA4cOgwjz0/kfWbtyAiPDFkEAnn1gvEbmSzYMkKxk58171PiW255dqu2ZbvP3iYkS9OZsv2FPc+3XsLdePcd3e6vO+9lC1bmpASJQgJCeHjcU8EYhe8sqH5JyEi/YBvVDXnPblylnsb961Mpvky3w9xPaSqo533cc42Gvqw3j3AHlV9p4DbvxM4rKpvFaSevGS6XIyeMoPXht1MVHhF/jPyFdo2aUB8bFRWmY+//ZXasVV4+f6b2HPgEN2HvsgVrS4gLiaSqaMHZ9XTcfAY2jfN9TiigOmc2J66dWrR4NxLaN7sQiaMf5qWl3T1WrbJhecTFhaabd4PPyzgyy+/AaBRo3P48IOJNGzUxtvqxUaPLh35T89uPPTkc4EOxWeZmS5GvfwGk8Y+QnRkBL3vGE67lk2Jr1ktq8zrH3xOg/g4/vv4UP7+dyujX36D158dCcDYCW/R6qIEXnj0ftLTM0g7ejRQu5IlM9PFqAlTmDT6QaIrh9P77pG0a34h8TVP3BT+9Y9n0CC+Bv8deQ9/b9nG6AlTeH3M8Kzlb455iEqhFQIR/illBnk3Y2GOxewHxBRi/afrofyuICIlgZuBD/yw/TeBu/xQzymt2phE9agIqlUJp1TJkiRefD5zl67JVkYEUtOOoqqkHjlGaLkyhJTI/iuxaPVGqlcJJ6ZypcIO2Wddu17Ou++7z3EW/baM0LBQoqOr5CpXokQJxo4ZwbDhT2Wbf/hwatb7cmXLokFw5btpQiNCKxa/D8BTWbluAzVioqkeE0WpUiXp3LYlPy7M3gLe+E8SzRs3AqB2jVi27tjJrr37OHQ4laUr13B15/YAlCpVkorlyxX5PuS08q+N1IiJonrVKu59anMxP+48vNYAACAASURBVP66NFuZjf9upfkF5wFQu3oMW5N3sWvv/kCEmy9+fJ5ZQPiUzEQkTkTWisgUEVkhItNEpKyzrImIzBORpSIyR0SqOo/Abgq8LyLLRaSMiIwUkcUiskpEJkk+7vvvbRvO/LkiMlZEfhORv0SktTO/rIhMdWL9WEQWiUhTERkDlHFiet+pPkREJovIahH5RkTKeAmhPbBMVTOc+uuIyHci8oeILBOReBFp68Q41YlljIj0cWJbKSLxAKqaCmwWkWa+7v/pSNm7n+jwEy2SKuGhJO89kK1M744t+HtbCpfdOYZew8fxwI1XUiJHMpv9ywoSW1xQmKHmW2xMNElbTjT4tyZtJzYmOle5O27/P76c+Q07duR+9l/37omsWjmPGdOncOut9xdqvP+rUnbtIbpKRNZ0VGQEybv3ZCtTP74m3y1YBMDKtRvYnryT5J17SNqeQqXQijzy7Ctcc9sDPPr8RFLTjhRp/N6k7NpLdGR41nRU5XCSd+/NVqZ+7Rp89/MSAFau28j2lF0k73Lvtwjc9vBYrh08gk9m/VB0gftA1bdXcZWflll9YJKqng8cAG4XkVLAy0AvVW2Cu9UxyukaXAL0UdUEVU0DxqvqRU6XXhngSl82erJteBQpqarNgHuAR515twN7nVifBJoAqOowIM2JqY9Tti4wQVXPA/YBPb2E0QrwPP1631nnAqAlsN2ZfwFwN9AIuBGo58T2Ou6nqh63BGjtZV+zHnr3xuff5vGTOTVvv3Q5zx5+XvkXDWrG8N34YUwdNZin3/mSQ6knPjDSMzKYt2wNnZrn2QtbpLydB+VsXVWtGkWvnlcyfsKbXuuYPn02DRu1oWev/jz+2NBCifN/nbcWr+T4LezfuwcHDh2m121D+eCLr2lQpxYlQ0qQmZnJmvWbuK5rJz557RnKlD6bNz4q0E3V/UJzPZbLyz5d09W9T3c8zAczvqVBfE1Khrg/at95fiRTxz/Fq08O4aOZ37Fk5doiidsXLhWfXsVVfq6ZbVHVhc7793B3lc0GGgLfOh8wIZz4YM+pnYg8AJQFwoHVwJc+bLd+Htv4zPl/KRDnvL8E+C+Aqq4SkRWnqH+Tqi73UoenqsAaABGpAMSq6udO/Uec+QCLVXW7M70R+MZZfyXQzqO+FKBBzo14PvTuyOJPC3QOFBUeyo49J7o2Uvbsp0qlitnKTJ+3jJu7XoqIUCM6gtjISmzavpNG8e6L1Qv++IsGcTFEFIP+/UED+9K/v/v8Y8mS5VSrfqIHO7ZaVbZtT85WvnFCQ+Lj41i3xv0rW7ZsGdb+uYAG516SrdxPCxZRu3ZNIiIqsTvHGbYpmKjICHak7M6aTt65myoR2bury5cry1NDbwfcyS/xhjuJja7CkaPHiIqM4Pxz6gLQ8dKLeePDwCezqMrh7Nh5onWZvGsPVSLCspUpX64MT93nfviyqpLY7z5io9zd4Mf3PyIslA4tm7Jq3UaaNsr1URAQxbkL0Rf5aZnl/HBV3Cf7q52WToKqNlLVTjlXFJHSwCu4W1eNgMlAaR+3m9c2jl8VzuREcs7PUfG8quxZh6c0j3hPVbdnXS6PaVeOeks7dRaa82rH8u+OXSSl7CE9I4PZv66gzYXnZCsTXTmURas3ArB7/0E2b99FtSonulC+/uUPOheTLsZXJ06h6UWdaHpRJ2bMmMONfXoB0LzZhRzYfyBXV+Ksr7+nWo3G1Kl3MXXqXUxqalpWIouPj8sq1zihIWedVcoSWSFoWD+ef7ZuJ2l7CunpGXw992fatmyarcyBQ4dJT88A4NNZ39Ok0TmUL1eWyuFhREdGsMnpTl60bGW2gSOB0rBebf7ZtoOkHc4+zfuVthdfmK1Mtn2aPZcmjepTvlwZUo8c4XCq+88+9cgRfl62kjpx1XNtI1D+l1pmNUSkhar+AlwPLADWAZHH5ztdgvVUdTVwEDh+Sn88EewSkfJAL8DXUYqn2sbJLACuBX4UkXNxd/sdly4ipVQ13cftg7tVVgdAVQ+ISJKI9FDVL0TkbNytxfyoByzMs1QBlAwJYXjfbgx65i1cLqVHmybUqRbF1O/d1yeu7dCcAT3aM+K1afQc9l8U5Z7rLqdSBfdF9rSjx/h11QZG3HxVYYZ5WmZ9/T2Jie1Zt2YhqWlp3HLLfVnLvpz+DgMGDmV7jpaap6uv6sINN/QiPT2DI2lH+E+fQUURdoEMfXQMi39fwb59B+jQ4wZu738jPbteHuiwTqlkSAgPDb6ZgcNGkelycVViO+rEVWeqM5L02q6d+PvfrTw8djwlSpQgvmY1Hr9/YNb6w++8mWFPjyM9PYNqVavwpNOCC6SSISE8NOgmBj7yLJmZLq7qdCl1alZj6lffA3DtFR34e8s2Hn7uNfc+1Yjl8XtuAWD33gPc8+RLgHtUZJe2Lbik6fkB25ecMotxovKF+DKSyxnCPguYj/sa0XrgRlVNFZEEYBwQijs5vqSqk0WkJzAadwukBfAw7ieObga2AP+o6mO+DM0/xTbmAkNUdYmIVAaWqGqciJQDpuBOGr/j7qbsrarrRWQs0A1Y5sSUNTRfRIYA5VX1sRyx1ATeVdVLnem6wGu4H/edDlwD1HBiudIp4xlb2xzLlgGdVHXXyX7mBe1mLI7Ktyr0QZwBkbbtp0CH4HeadjDQIRSO9MAP7y8MZ9VuVuBMtDC6l0+fOa12TCuWWS8/ycyn72MVByISApRS1SPOKMLvcbfmjhWgzs+BB1R1fQFjawzcp6o3nqqcJbPgYcksiFgyO6mffExmrYtpMjtT7wBSFncXYync17gGFSSROYbhHghSoGSGuzU3ooB1GGOMX2m+hhoUPz4lM1XdjLurLiio6kHc33PzZ53rcF+/K2g9BRtzb4wxhcAV5H1BZ2rLzBhjTD5kFuoNoQqfJTNjjDG4Ah1AAQV3KjbGGOMXivj08oWIJIrIOhHZICLDvCzv49xucIWI/CwiBf5Cq7XMjDHG+K1l5owmnwB0BJKAxSIyQ1X/9Ci2CWijqntFpDPuOx81L8h2LZkZY4zxZzdjM2CDqv4NICIfAd2BrGSmqj97lP8VKPDtXayb0RhjjM/djJ43RHdeA3JUFYv7xhjHJTnzTqY/8HVB47eWmTHGGDJ8fCqX5w3RT8JbRV4H/otIO9zJ7BJvy/PDkpkxxhjv2eb0JAGed1CuBmzLWUhEzsf9eKzOqro75/L8sm5GY4wxuHx8+WAxUFdEaonIWbjvyTvDs4CI1MD9+K4bVfUvf8RvLTNjjDG4fOxmzIuqZojIncAc3E8UeVNVV4vIQGf5RGAkEAG84jwLMkNVC3TXJktmxhhj/NnNiKrOwv2kFc95Ez3e3wLc4sdNWjIzxhgT/HcAsWRmjDHG59GMxZUlM2OMMX7tZgwES2bFlO7fGegQ/K7i2WUDHUKhOBMfZCllKgQ6hEKhrsxAh1BsuYK7YWbJzBhjjF0zM8YYcwawbkZjjDFBL8O6GY0xxgQ762Y0xhgT9NRaZsYYY4KdtcyMMcYEPUtmxhhjgp6NZjTGGBP0bDSjMcaYoGfdjMYYY4KedTMaY4wJenZvRmOMMUHPuhmNMcYEPetmNMYYE/QygjydWTIzxhgT5KnMktkZbeHqzTwzbS4ul4urWjXk5k7Nsi0/mHaUh9/+mh17D5KR6eKmy5rSo8V57Nh7kEemzGb3gVREoOcljejT7sIA7YV3Tz8zgo6d2pCWlsYdAx9kxR9/5iozbsJoEho3RETYuGEzdwx8kMOHUxl89y30urYbACVLhlCvfjx1azVn3979Rb0bWRb8tpyxr7xFpsvF1Z07cMv1PbIt33/wECOfe5Ut25I5+6xSPDFkEHVr1QDgwKHDPPb8RNZv3oKI8MSQQSScWy8Qu5Evj4x+gfkLfyO8UhhfvDcx0OH4bMHi5Yx99R33sUpsxy29u2dbvv/gIUY+/xpbtidz9lln8cR9t1G3VnXAOVYvTGL95iRE4In7bys2xyrYr5mVKKoNiUg/EYnxodzbItLrNOofKCI3eZkfJyKrnPcJItLFY9ljIjLEh7pFRH4QkYr5jctLXd+JSKWC1pOXTJeLp6f+wIQ7evDZiL7MXrKOjdt3Zyvz8bw/qF01gqkP3cjr91zDC5/NIz0jk5ASwv1XX8rnI/vy7tDr+Xj+H7nWDaTLOrUhPr4mTRMu4967RvD8i094LffwsNFc2rIbrVt0JSlpG7fcdgMAL//3ddq06kabVt144rHnWbjgt4AmssxMF6NefoNXRj/E9Dde5OsfF7Lxn6RsZV7/4HMaxMfx2eTnGPXgnYx95e2sZWMnvEWrixL48q2X+PS1Z6ldI7aI9+D09OjSkYkvPBXoMPIlM9PFqPFv8cqoB5k++Tm+nvtz7mP14XQaxNfks9eeYdTQQYx9dUrWsrGvTKHVRRfw5ZvP8+nEscXqWLnEt5cvRCRRRNaJyAYRGeZluYjIOGf5ChEp8NlykSUzoB+QZzI7Xao6UVXfyaNYAtAljzLedAH+UNUDp7FuTu8Ct/uhnlNatXkH1SPDqFY5jFIlQ7i8SX3mrtiYrYwIHD5yDFUl7Wg6oWVLE1KiBJGh5TmnRhQA5UqfRe2ocFL2HSrskH3W5YrL+OjDLwBYsng5FcMqEBUVmavcwYMnYi5dujTqpR+lZ68r+WzazEKL1Rcr122gRkw01WOiKFWqJJ3btuTHhYuzldn4TxLNGzcCoHaNWLbu2Mmuvfs4dDiVpSvXcHXn9gCUKlWSiuXLFfk+nI6mCY0IrVgh0GHkS9axquocqzYt+PHnJdnKbPw3ieaNGwLOsUr2PFZruTqxHVD8jpUL9emVFxEJASYAnYFzgetF5NwcxToDdZ3XAODVgsZ/WsnMae2sFZEpTladJiJlnWVNRGSeiCwVkTkiUtVpaTUF3heR5SJSRkRGishiEVklIpNE5KQ5X0SqiMhS5/0FIqIiUsOZ3igiZT1bWU4Mf4jIL8AdzryzgCeA65wYrnOqP1dE5orI3yJy10lC6ANM94jnJme//xCRd515b4vIqyLyo1NXGxF5U0TWiMjbHnXNAK7P548831L2HSK60okPiqiw8rkSUu82CWzasYeOD02i16h3GXpNW0qUyH4Ytu7ez9qknTSKiy7skH1WNSaKrVu3Z01v27qDqjFRXsuOf3UMazf+Qt16tZk8Mfu5TpkypelwWWtmTJ9TqPHmJWXXHqKrRGRNR0VGkLx7T7Yy9eNr8t2CRQCsXLuB7ck7Sd65h6TtKVQKrcgjz77CNbc9wKPPTyQ17UiRxv+/JGXXXqIjcx6rvdnK1K9dk+8WuE9G3Mdql/tY7UihUlhFHnluItcMGsajL0wqVscq08eXD5oBG1T1b1U9BnwEdM9Rpjvwjrr9CoSJSNWCxF+Qlll9YJKqng8cAG4XkVLAy0AvVW0CvAmMUtVpwBKgj6omqGoaMF5VL1LVhkAZ4MqTbUhVU4DSTjdfa6eu1iJSE0hR1dQcq7wF3KWqLTzqOAaMBD52YvjYWdQAuBz3AXjU2YecWgHHk+l5wMNAe1W9ALjbo1wloD1wL/Al8CJwHtBIRBKcOPYCZ4tIBIXI2/lTzvOFn//cTP1qkXw7egAfD7+BMVN/5FDa0azlqUeOMWTyTIb2akP5MmcXZrj54u28R701u4A7Bw3j3Lqt+GvdRq7qeUW2ZYmd27No0bKAdjGC99iF7PvYv3cPDhw6TK/bhvLBF1/ToE4tSoaUIDMzkzXrN3Fd10588tozlCl9Nm989EVRhf4/R738ZeX8dex/XTf3sRo4jA+mz6FBnThKhoScOFZXduSTV8e4j9XHM4oo8rz5q2UGxAJbPKaTnHn5LZMvBUlmW1R1ofP+PeAS3AmuIfCtiCwHHgGqnWT9diKySERW4k4A5+WxvZ9xJ5VLgdHO/62BnzwLiUgoEKaq85xZ7+ZR71eqelRVdwEpgLdT/HBVPei8bw9Mc8qjqp6n0F+q+5NpJZCsqitV1QWsBuI8yqXgpctVRAaIyBIRWfLGVz/lXJwvUWHl2bH3YNZ08r5DRIZm79KY/uufdEiog4hQo0oYsRGhbEp2n2WmZ2Zy/+sz6XJRAzok1C1QLP7Q/9Y+zFs4g3kLZ7BjezKxsSdO4mJio9mxPeWk67pcLj7/dBZdu1+ebf5Vva7g008C28UI7rP7HSknrkkm79xNlYjsl1XLlyvLU0NvZ9przzL6wTvZu/8AsdFViIqMICoygvPPcR+jjpdezJr1m4o0/v8lUZXD2bEzx7EK93Kshgxk2sQxjH7gdudYRRJVOYKoyHDOP6cOAB1bN2fNhuJzrNTHl+fnlPMakKMqb71sObOgL2XypSDJLOeGFXeAq52WT4KqNlLVTjlXFJHSwCu4W3CNgMlA6Ty29xPu5FUTd5ffBbgT6Pyc1XuJ7VSOerzPxPsIzwwROf6zOlX9x+ty5ajXlaPe0kBazpVVdZKqNlXVpv2vaO1L7Cd1Xs1o/k3Zy9Zd+0nPyGTO0nW0aVQ7W5mqlSqwaJ375Gj3gcNsTt5DtcqhqCqPv/cttaLDubFDkwLF4S9vTH4/a9DGVzO/o7cz2q/pRQkc2H+Q5OSdudapVbtG1vvELu1Y/9eJa4YVKpanVatmfP3Vd4UffB4a1o/nn63bSdqeQnp6Bl/P/Zm2LZtmK3Pg0GHS0zMA+HTW9zRpdA7ly5WlcngY0ZERbNqyDYBFy1YSX/Nk54+moNzHaseJYzXvF9q2yP43ku1Yff3DyY/V76uIr1F8jpXLx5fn55TzmpSjqiSgusd0NWDbaZTJl4IMza8hIi1U9Rfc14AWAOuAyOPznS67eqq6GjgIHL+Iczxx7RKR8kAvYFoe25sPPAXMV1WXiOzBPTBjuGchVd0nIvtF5BJVXYD7etdxnjHkxzqgNrAB+B74XEReVNXdIhKeo3V2Ss61wWhg82nE4bOSISUYdm17Bk34DJdL6d7iPOrEVOaTn/4A4JrWF3Br5+aMfHcOvUa9gyrc06M1lcqX4fcNW5n52xrqxlTm2tHvATC4WytaN6xVmCH77Ns5c+nYqQ1L//ietLQ07hx0YrDUx9Mmc/edD5OcvJNXXnuGChXKIyKsWrmWIfc+mlXuyq6d+PGHBaSm5jqnKHIlQ0J4aPDNDBw2ikyXi6sS21EnrjpTv/wGgGu7duLvf7fy8NjxlChRgvia1Xj8/oFZ6w+/82aGPT2O9PQMqlWtwpNDC318kV8MfXQMi39fwb59B+jQ4wZu738jPbtenveKAVQyJISH7uzHwIeedh+ry9u6j9XMbwG49sqO7mP1zKvOsYrl8ftONFyG39GPYWPGk56RQbXoKJ4cclugdiUXH7sQfbEYqCsitYCtQG/gPznKzADuFJGPgObAflXdTgHIya41nHIlkThgFu4E0xJYD9yoqqnOtaFxQCjuZPmSqk4WkZ64uwfTgBa4rzv1xv2hvgX4R1UfcwZLzHSus+Xc7r/AU6o6SUQeAno71+wQkceAQ6r6nIgcv16XCszB3QJsKCLhznQp4GngnOPrOHWsAq5U1c05tjsC2K6qrzvTfYGhuFtyv6tqP8+4nZ/PTOd6IDmWNQWGq2rPU/2M076bGOzfYcwl9qrnAx1CodjxZ17nYcFHygTXKENf6eF9gQ6hUJxV88IC3yb43rjePn3mvLj5ozy3Je6vQL0EhABvquooERkI7pHnzkn9eCAR9+f0/6nqkpNW6IOCJLOsD+sznTPK5h1V7eiHuv4LzFDV709VzpJZ8LBkFjwsmZ3cXXHX+fSZM27zx8Xy/vpF+T2zoOU0fyeLH740DazKK5EZY0xR8/WaWXF1WtfMnG64/4lW2XGqOtVP9Uz2Rz3GGONPfrxmFhB2b0ZjjDFBnsosmRljjMFaZsYYY84AmZbMjDHGBLviPLjDF5bMjDHGeL3vZDCxZGaMMcZaZsYYY4Kf6zRuoFGcWDIzxhgT5J2MlsyMMcYAmUHe0WjJzBhjTJCnMktmxhhjsC9NG2OMOQPY0HxjjDFBz7oZjTHGBL3TebZlcWLJrLhKPRToCPzuwNHUQIdQONKPBjoCv1NXZqBDKBRSLizQIRRbGdbNaIwxJtjZNTNjjDFBz0YzGmOMCXp2zcwYY0zQs9GMxhhjgl6w386qRKADMMYYE3iq6tOroEQkXES+FZH1zv+VvJSpLiI/isgaEVktInfnVa8lM2OMMbhQn15+MAz4XlXrAt870zllAPer6jnAxcAdInLuqSq1ZGaMMQb18Z8fdAemOO+nAD1yxaK6XVWXOe8PAmuA2FNVasnMGGMMLlWfXiIyQESWeLwG5HNTUaq6HdxJC6hyqsIiEgc0BhadqpwNADHGGONzm0tVJwGTTlVGRL4Dor0sejg/MYlIeeBT4B5VPXCqspbMjDHGkOHH0YyqetnJlolIsohUVdXtIlIVSDlJuVK4E9n7qvpZXtu0bkZjjDFFNpoRmAH0dd73BabnLCAiArwBrFHVF3yp1JKZMcaYohzNOAboKCLrgY7ONCISIyKznDKtgBuB9iKy3Hl1OVWl1s1ojDGmyG40rKq7gQ5e5m8DujjvFwCSn3otmRljjLF7MxpjjAl+dtd8Y4wxQS9Tg/vejJbMzmAL127hmRm/4HIpVzWrz83tE7Itf3vuH8xatgGATJeyKWUfPz52A6FlS/Pu/JV8/ttaBKFu1XAev/ZSzi5VfH5dXnzhCTontic1LY3+/e/l9+WrTlr2pRefpF/f6wgLrwdA166dePyxobhcSkZGBvff/ygLf15cVKF7tWDJCsZOfJdMl4urE9tyy7Vdsy3ff/AwI1+czJbtKZx9VimeuPcW6sZVB+DyvvdStmxpQkqUICQkhI/HPRGIXfBqweLljH31HWe/2nFL7+7Zlu8/eIiRz7/Glu3JnH3WWTxx323UreXerwOHDvPYC5NYvzkJEXji/ttIOLdeIHYjXx4Z/QLzF/5GeKUwvnhvYqDD8Zk9nPMMICJhwH9U9ZVC3k4P4C9V/bMwtwOQ6XLx9OcLmTigC1Gh5egz7gvanFeT+KgT9/Ts1/YC+rW9AIB5f/7De/NXElq2NMn7D/PhglV8NvQaSpcqydB3v2P28r/pflHx+CDpnNieunVq0eDcS2je7EImjH+alpd09Vq2yYXnExYWmm3eDz8s4MsvvwGgUaNz+PCDiTRs1KbQ4z6ZzEwXoyZMYdLoB4muHE7vu0fSrvmFxNc8cfee1z+eQYP4Gvx35D38vWUboydM4fUxw7OWvznmISqFVghE+CeVmeli1Pi3mDTmIaIrR9B78MO0a9GE+JrVssq8/uF0GsTX5L+P3c/f/25l9Pi3eP2ZRwAY+8oUWl10AS+MvJf09AzSjh4N1K7kS48uHflPz2489ORzgQ4lX1xBfs3Mhua7hQG3+1pY3E7nZ9cDOOXNMv1l1b87qV65ItUiKlKqZAiXJ8Qzd/U/Jy3/9e8bSWxcJ2s606UcTc8gI9PFkfQMIiuWLYqwfdK16+W8+/40ABb9tozQsFCio3PfEadEiRKMHTOCYcOfyjb/8OHUrPflypYN+IXvlX9tpEZMFNWrVqFUqZJ0bnMxP/66NFuZjf9upfkF5wFQu3oMW5N3sWvv/kCE67OV6zZQIyaa6lWjnP1qwY8/L8lWZuO/STRv3BCA2jVi2Zq8k11793HocCpLV67l6sR2AJQqVZKK5csV+T6cjqYJjQitWLxOLHxRhPdmLBSWzNzGAPHOdxleFJHvRWSZiKwUke7gvj+Y8ziCV4BlQHURGSEia53HGHwoIkOcsvEiMltElorITyLSQERaAt2AZ53txBfmDqUcOEx0WPms6ajQcqTsP+y1bNqxDH5el8RljeKyyt7U5nwSR31Ixyffp3zps2hZv5rXdQMhNiaapC3bsqa3Jm0nNib3nXPuuP3/+HLmN+zYkfsGA927J7Jq5TxmTJ/CrbfeX6jx5iVl116iI8OzpqMqh5O8e2+2MvVr1+A7JxGsXLeR7Sm7SN61BwARuO3hsVw7eASfzPqh6ALPg3u/IrKmoyIjvOxXTb5b4O7iXbl2A9uTd5G8cw9JO1KoFFaRR56byDWDhvHoC5NITTtSpPH/r/H13ozFlSUzt2HARlVNAIYCV6nqhUA74Hnn2+gA9YF3VLUxEAn0xH0DzKuBph71TQIGq2oTYAjwiqr+jPub70NVNUFVN+YMwvMGnm/M+bVAO+Ttd05O8q2N+X/+Q0JcFKFlSwNwIPUoc1dv5qvhvflmRB/SjmXw1dL1BYrHn8TLjuRsXVWtGkWvnlcyfsKbXuuYPn02DRu1oWev/jz+2NBCidNX3s52JcdXbPpf05UDhw7T646H+WDGtzSIr0nJEPef7zvPj2Tq+Kd49ckhfDTzO5asXFskcefF637lOHT9r+vm3q+Bw/hg+hwa1ImjZEgImZmZrFm/ieuu7Mgnr46hTOmzeePjGUUU+f+mTHX59Cqu7JpZbgKMFpFLcT9JPBaIcpb9o6rHs8wlwHRVTQMQkS+d/8sDLYFPPD50z/Zlw5438Eyb8VyBToGiQsuxY9+hrOnk/YeJrOi9m2b28o0kNj7RUPx1/VZiwysQXr4MAB0axrH8n2SuaFK3ICEVyKCBfenfvw8AS5Ysp1r1mKxlsdWqsm17crbyjRMaEh8fx7o1CwEoW7YMa/9cQINzL8lW7qcFi6hduyYREZXYnaPVUFSiKoezY+eerOnkXXuoEhGWrUz5cmV46j73zclVlcR+9xEb5e5arRLhvg4aERZKh5ZNWbVuI00bNSii6E/OvV+7s6aTd+6mSnj25zCWL1eWp4YMBJz9uukuYqMjOXL0GFGR4Zx/jrvru2Pr/2/vvsPsqso9jn9/CSAQeg+BhB6EJJKiEIpUkSJI1QsERRAEC3J55D4UvTQVu171gjQhgKig3EszwDUU6WBCCyAgJShdIAWSQMrv/rH2kDPDX0WSRgAAFgNJREFUJEzmnMyavff7eZ55Zs4+50zexQzz7tXetSUX/v59VY9CC/XmIcSuiJ7Z+x1C6nWNLHpqrwBLF881jtMtaHd6H2BK0ftq+/jw4gu3c5uvuzrP/2saL7wxjdlz5nLjg0+z/WYD3/e66TPfZcIzL7Pj5oPeu9Z/5eV4+PlXmfnuHGxz799fZIM1Vnrfe3vSOb8ay6iP7sqoj+7KNdfcyKGHHADAlh8bwbSp0943lPinceNZZ+BwNtpkKzbaZCtmzJj5XiLbcMP13nvd8C2GsNRSS2ZLZABDNtmAyS++zD9ffpXZs+cw7rZ72GGrEe1eM+2tt5k9ew4Af7zhVkYOHcxy/ZZhxqxZvD1jJgAzZs3iromPsFGxyjG3IYM3ZPILL/PPl9radTc7jB7Z7jXt2jXuZkYO/TDL9VuW1VZZibVWX5Vni+Hkex+YxIYDe89QdxWVfZgxembJdKBtxnZF4FXbsyXtCAxawHvuAM6VdBbpv+OewPm2p0l6VtKBtq8shiiH2X6ow7+zWC3Rtw8n7rM1x5w/jnnzzKc/NpiN1lqFK+9OCykPHJ3Wodw86TlGbzKAZZZa8r33Dh24BrsM3YCDfnYVffv0YdMBq7L/Vj2ejxfoT+PGs9tuO/HE43cyY+ZMvvjF49977tqrL+Goo0/gpQ49tUb77bsHY8YcwOzZc5g1cxYHH3JMT4S9QEv07cvJx3yOo7/5Q+bOnce+u36cjQatwxXXjwfgM3vuzDP/eJFTfnQuffr0YcOBAzj9uC8C8Pqb0zjuzJ8BafXgHjuMZttRw7K1pdESffty8lcP4+iTz2LuvHns+8kd2Gi9dbniuv8D4DOf+gTPPP8Cp/zgnNSuQQM4/fj5R2Od9JXDOPF7v2T2nDmss9aanPmNL+VqyiI54dTvcf8DDzNlyjR23mcMXz7iUPbf65O5w/pAZe+ZKfdKrt5C0uXAMOB+YFNgSeBBUsHL3YuXXWd7SMN7TgMOAiYDrwG32j5f0vrAOUD/4vv8zvYZkrYBzgfeAQ7obN6sTbPDjL3R8gf8NHcIi8WMv/1P7hBar28173PVL+8Iw+Ky5GobLFIdw86sv+pHuvQ359nXH2r631ocqvkb2w22D+7Cy4Z0ePwj26dJWhb4C/Dj4ns9C+zWyb9xJz20ND+EEBZFlLOqt/MkbUaaUxtre2LugEIIoTt680rFrohk1oQu9uZCCKHXK/uUUySzEEIIvXqlYldEMgshhFD61YyRzEIIIcQwYwghhPKL1YwhhBBKb+68WM0YQgih5Mo+zBi1GUMIITAPd+mjWZJWKY7Neqr4vPJCXttX0gOSrvug7xvJLIQQAra79NECJwLjbW8MjC8eL8jXgce78k0jmYUQQujJqvmfBsYWX48F9unsRZLWIRVwv6Ar3zTmzEIIIfRkOas1bb8EYPslSWss4HU/A/6DLp40EskshBBCl4cQJR0FHNVw6bziYOHG1/wZWKuTt5/SxX/jU6SjuCZI2qEr74lkFkIIocsVQIrEdd4HvGaXBT0n6RVJ/YteWX/g1U5etg2wt6Q9SIXcV5B0me0xC/q+MWcWQgihJxeAXAN8vvj688DVncRyku11bK8H/Btw88ISGUQyCyGEQI8ms+8Bn5D0FPCJ4jGS1pb0p+5+0zhpOiDpqI5j3mVXxTZBNdtVxTZBddvVW0XPLED7ydyqqGKboJrtqmKboLrt6pUimYUQQii9SGYhhBBKL5JZgA9YZltSVWwTVLNdVWwTVLddvVIsAAkhhFB60TMLIYRQepHMQgghlF4ksxBCCKUXtRlrRtJoYAywHdAfmAlMAq4HLrM9NWN43SZpFKlNazO/TX+2/UbWwJpU4XatzPw2PWf3XMn2xUXS+raf/aBrYfGIBSA1Imkc8CKpFtpfSQU+lwY2AXYE9gJ+YvuabEEuIkmHAccCzwITaN+mbUh//L9l+/lcMXZHFdslaUXgK8BBwFLAa6Q2rQncA5xt+5Z8ETZH0kTbIzpcm2B7ZK6Y6iR6ZvVyqO1/dbj2FjCx+PixpNV6Pqym9AO2sT2zsyclbQFsDJTmj36hiu36A3AJsJ3tKY1PSBoJHCppA9sXZomumyRtCmwOrChpv4anViAl69ADomdWY5JWoOGGpuxDVyHkIOnTpNOS9yZVhG8zHfid7buyBFYzkcxqSNKXgDNI8xVtvwC2vUG+qJojaX3ga8B6tE/Qe+eKqRUq3K5hvL9NV2ULqAUkjbZ9d+446iqGGevpG8DmnQw5ltn/AhcC1wKlX0zQoHLtkvRrYBjwKPPbZKDUyQx4XdJ4YE3bQ4qEvbftb+cOrA6iZ1ZDkm4A9rM9I3csrSLpXttb5o6j1arYLkmP2d4sdxytJuk24ATgXNvDi2uTbA/JG1k9RM+snk4C7pJ0L/BO20Xbx+YLqWn/JelU4Cbat2livpBaoortulvSZrYfyx1Iiy1r+z5Jjdfm5AqmbiKZ1dO5wM3AI1Rk6AoYChwK7ET7oaudskXUGlVs11hSQnuZlKBFmrMdljespv1L0oYU89CSDgBeyhtSfcQwYw1Jusv21rnjaCVJfwOG2X43dyytVMV2Sfo7cDwdbqZsT84WVAtI2oBUKX9r4E3SHsExtp/LGVddRM+snm6RdBRpUUHj0FWZl+Y/BKxE2lxcJVVs1/Nl2pjfVbafAXaR1A/oY3t67pjqJHpmNSSps/I6ZV+afytphdz9tE/QZV/CfisVa5eks0kJuuPNVKlXM0o6vpPLU4EJth/s6XjqJpJZqARJ23d23fZtPR1LK1WxXZIu6uSybR/e48G0kKTLgVGkJA2wJ+kmZFPgSts/yBVbHUQyqyFJXwF+01ZSqCj6epDts/NG1n3F5uKXbM8qHi9D2u/zXNbAmlTVdlWRpBuB/W2/VTxejlTCa19S76xy2xF6kzgCpp6ObKyNZ/tN4MiM8bTClbRfmTm3uFZ2lWuXpLGSVmp4vHKxkbrsBgKNC3VmA4OK+prvdP6W0CqxAKSe+kiSi265pL6kKuZltkTjij/b70oqe5ugmu0a1vFmStLwnAG1yOXAPZKuLh7vBfy2WBBStT11vU70zOrpRuAKSTtL2gn4LXBD5pia9Zqk9xZFFMVfq1Cuq4rt6lMMbQMgaRVKfmOttFP6YtIIxxTSwo+jbZ9h+23bh+SMrw5izqyGJPUBjgJ2IW1YvQm4wPbcrIE1odis+hvSgY8A/yQdefN0vqiaV8V2SfocqQrNH0gbjD8DfMf2pVkDa1KcXZZXJLNQKcWku6q2x6dq7ZK0GamKiYDxVShtJem/gYtt3587ljqKZFYjkq4lVSi4wfbsDs9tABxGOsK+NJPxksYAl9vutCxX0bPpb/uOno2sOVVsl6Tl2lb6NfOa3krSY6STwCcDb1OdMl2lUOpx6rDIjiSVEfqZpDeYf2z9+sDfgV/avnoh7++NVgUekDQBmMD8Nm0EbE+aXzoxX3jdVsV2XS3pQeBq0lL1t+G9G6kdScON55OGH8to99wB1Fn0zGpK0npAf9IBnU+W+TiYYjXmTsA2zG/T48A428/njK0ZVWyXpD2AQ0htWoW0fP0J4HrgQtsvZwyvJSStQbrxAKCsP6uyiWQWQggtUKw6/TFpsc6rwCDgcdubZw2sJmJpfgghtMaZwFakkY71gZ2BO/OGVB+RzEIIoTVm236dtI+uj+1bgC1yB1UXsQAkhBBaY0qxheIvwG8kvUqaEww9IJJZDUnaBjiNNKa/BPOXEJf5CJgPAfsD69Hwe237jFwxtUKF29UXWJP2bSr7QomHgBnAv5MWuawILJc1ohqJZFZPF5L+h5tAKlxbBVdTnB1FtYq6Vq5dkr4GnAq8wvwiyiad21ZmOxb7AucBYwEkPZw3pPqIZFZPU22Pyx1Ei61je7fcQSwGVWzX14HBxfxS6Uk6BvgysGGH5LU8sQCkx0QyqxFJI4ovb5H0Q+Aq2p/0OzFLYK1xl6Shth/JHUiLVbFd/yD1NqvicmAccBbtN7JPt/1GnpDqJ/aZ1YikWxbytG3v1GPBtIikR0hDVEsAGwPPkBJ0qUsJVbFdko4vvtwcGEzaKN14M/WTHHGFaoieWY3Y3hFS+SDbzzQ+V5QUKqNP5Q5gMaliu5YvPj9ffCzF/HP04q46NCV6ZjUkaaLtER2ulfr4CkmX2j70g66VTRXbJelA21d+0LUQFkX0zGpE0qakIZ4VJe3X8NQKNNSSK6l2JYOKpd+lTc4Nqtiuk4COiauzayF0WSSzehlMGr5aiXSke5vppIr6pSPpJOBkYBlJ09ouA++SjrsppSq2S9LuwB7AAEk/b3hqBWBOnqhCVcQwYw1JGm377txxtJKks2yflDuOVqtSuyR9BBgOnA78Z8NT04FbbL+ZJbBQCZHMakjSL3j/hPtU4K9lO8+sYbtBp0q+3WBB7ZsKTLZdyt6MpCU7Hg4bQrMimdWQpPOATZk/R7E/8CiwLvCM7eNyxbaoGrYbLA2MIpUUEqmaxL22t80VWytIugcYATxMatdQUhtXBY62fVPG8BZJw3aDTpVxu0HoPWLOrJ42AnZqu7OXdA5wE/AJoFSbcxu2G/wOOKptc7GkIcA3csbWIs8BR9h+FEDSZsAJpONGriL93MqibbvBV4rPlxafDyHVNAyh2yKZ1dMAoB/zqzD0A9a2PVdSWev/bdpYJcP2JElVOH5j07ZEBmD7MUnDbT8jKWdci8z2ZEiFrm1v0/DUiZLuBEpdPDnkFcmsnn4APCjpVtLQ1ceB70rqB/w5Z2BNeFzSBcBlpKGsMcDjeUNqiSeKnvPvisefBZ4squmXdd6pn6Rtbd8BIGlr0g1VCN0Wc2Y1Jak/8DFSMrvP9ouZQ2qKpKWBY0iJGdKZUufYnpUvquZJWoZUxHZb0s/qDuBsYBawrO23MobXLZJGAr8mHZECMAU4vOyLdUJekcxqStIA5p9nBoDtv+SLKNSNpBVIf4OqVHQ4ZBLDjDUk6fuk4apHaX+eVOmSmaQrbH9mQSvlyr5CrpODVAEo40GqksbYvqyh4HDbdSAKDYfmRDKrp31I50mVdbFHo68Xn6tYmBeqdZBq27zY8gt9VQjdEMOMNSRpHHBgGedbFkTS4cDttp/KHUsrSbrX9pa542glSUuXfS4z9D7RM6unGaTVjONpf57UsflCatp6wBhJg0i9mNtJye3BrFE1r4oHqU6S9ArpZ/QX4M6YNwvNip5ZDUn6fGfXbY/t6VharVj9dyRpw/QA230zh9SUBRyoWsqDVBtJGghsB2xDKj48xXYV9gWGTCKZ1VTxR3+g7Sdyx9IKkr5J+sO4HPAAaQn77bZfyhpYeB9J65AS2fbAR4A3gDtsn5U1sFBqkcxqSNJewI+ApWyvX1TKOMP23plD6zZJE0nHiFwP3AbcU4V5GUlrAt8lVWjZvShnNdr2hZlD6zZJ84D7ge+WrbB16L365A4gZHEaacP0FIBiXmn9nAE1qzg5e2fgPooak5LuyBtVS1wM3AisXTx+EihNIegFGA5cAhws6W5Jl0g6IndQodxiAUg9zbE9tUNtv1J30YvCwm1DV6OAf5AWGJTdaravKA7rxPYcSaVeom/7IUlPA0+TfmZjSJVbStvbDPlFMqunSZIOBvpK2hg4Frgrc0zN+j5pePHnwP0VOi/rbUmrUtxsSNqK+QWiS0nSX4EPkX7n7gA+3laEOITuijmzGpK0LHAKsCup3t+NwJlVmGOqmuJwzl8AQ4BJwOrAAbYfzhpYEyStbvu13HGEaolkFkIvJ2kJYDDpxuOJCvU6Q2iZSGY1IulaFn7Sb2lXM1aNpP0W9rztq3oqlhDKIObM6uVHuQMIXbbXQp4zqSJICKEQPbNQatHbLI/obYbFKXpmoeyit1ke0dsMi030zEIIIZRe9MxCJRT75c4CNgOWbrtexkMs60DSnsDmtP9ZnZEvolB2kcxqpOLzSxcBpwI/BXYEvkBayl5KVZ5fkvQrYFnSz+kC4ABSGbIQui2GGWtE0vYLe972bT0VS6tJmmB7pKRHbA8trt1ue7vcsXWHpIsW8rRtH95jwbSYpIdtD2v4vBxwle1dc8cWyit6ZjVS5mTVBbMk9QGekvRV4AVgjcwxdZvtL+SOYTGaWXyeIWlt4HVKXug65BfJrIYqOr90HGno6ljgTGAnoNNDSMumgvNL10laCfghMJE09H1B3pBC2cUwYw0VR6O0zS/tRTG/ZPvUrIG1gKQVSMNw03PH0goLml+yXdojUyR9yPY7bV+TkvSstmshdEecZ1ZPy9geT0pgk22fRurJlJakUZIeAR4mnWX2kKSRueNqga1tfw540/bpwGhg3cwxNevuti9sv2N7auO1ELojhhnrqVLzS4VfA1+2fTuApG1JKxyHZY2qeZWZX5K0FjAAWEbScOavNl2B1PsModsimdVTFeeXprclMgDbd0iqwlBjleaXPgkcBqwD/KTh+jTg5BwBheqIObMaq9L8kqSfkhL0b0l/8D8LvAn8EcD2xHzRdV8V55ck7W/7j7njCNUSyayGJI0iDcEtX1yaChxue0K+qJoj6ZaFPG3bpZwTlDTR9ogPulYmxXDjd4C1be8uaTNgtO0LM4cWSiyGGeupcvNLtnfMHUMrVXx+6aLi45Ti8ZPA74FIZqHbIpnVU+XmlyStCXyX6tztV3l+aTXbV0g6CcD2HElzcwcVyi2SWT3dJ+lc2s8v3SppBJR2fuliKnS3b3ssMLai80tvS1qVok6opK1IQ90hdFvMmdVQFeeXJN1v+6OSHrA9vLj2oO0tcsfWjCrOLxU3Tb8AhgCTgNWBA2w/nDWwUGrRM6uhqs0vFap6t1+5+SXbE4ui14NJc4FP2J6dOaxQcpHMaqiC80sAxwPXABtKupPibj9vSC1RufklSUsDXwa2Jd183C7pV7Zn5Y0slFmUs6qni4EbgbWLx0+SNlKXVjHPtz2wNfAlYPOKDFtVscd5Calw8i+AX5IKXl+aNaJQepHM6mk121cA8yDd7QNlv9s/kFRz8lFgH+D3bQtaSq5jj/MS4Gt5Q2raYNtH2L6l+DgK2CR3UKHcIpnVUxXv9r9le3qxZ+6TwFjgnMwxNa2iPc4Hit85ACRtCdyZMZ5QAbGasYaquJqsbRWjpLOAR2xf3riysaw6m18CSj2/JOlx0uKP54tLA4HHSSMFtl3azfshn0hmNSVpCSq0mkzSdaTq/7sAI0nV5u+z/ZGsgTVJ0hXAdOCy4tJBwMq2D8wXVXMkDVrY87Yn91QsoToimdVQMb90QzEs901gBPDtkm6WBkDSssBupF7ZU5L6A0Nt35Q5tKZIeqhjQu7sWgh1F3Nm9VS5+SXbM2xfZfup4vFLZU9khZhfCqELIpnVU9vKxT2Bc2xfDSyVMZ6wYFsCd0l6TtJzpBOZt5f0iKTSznGG0GqxabqeXihqM+4CfL84JytubHqn3XIHEEIZxJxZDVV1fimEUF+RzEIIIZReDC2FEEIovUhmIYQQSi+SWQghhNKLZBZCCKH0IpmFEEIovf8HvsAH0AKVH4AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corrs = frame.corr()\n",
    "sns.heatmap(corrs,annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien hier dat de sepal breedte een negatieve correlatie heeft, terwijl de petal lengtes, breedte en sepal lengte het meetste mee tellen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notitie: Deze dataset is al helemaal 'clean'; Data cleanup en Data preparation is hier niet nodig, deze stappen slaan we dus over. We zullen wel tijdens het organiseren van de testdata de data overzetten naar een list; kennelijk ontstaan er makkelijk errors als we direct een pandas dataframe gebruiken. Verder maken we ook dummies van y, zodat deze in ons netwerk passen.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stap 3 - Model Training\n",
    "Nu gaan we ons model trainen; we gaan ons neurale netwerk opzetten!\n",
    "We hebben te maken met drie verschillende classificeringen (0, 1 en 2), en vier mogelijke features (sepal length, sepal width, petal length, petal width)\n",
    "O.b.v. onze correlatie analyse willen we gebruik maken van de meest kansrijke features; De beste hiervoor zijn sepal length, petal length en petal width\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1                1.4               0.2\n",
       "1                  4.9                1.4               0.2\n",
       "2                  4.7                1.3               0.2\n",
       "3                  4.6                1.5               0.2\n",
       "4                  5.0                1.4               0.2\n",
       "..                 ...                ...               ...\n",
       "145                6.7                5.2               2.3\n",
       "146                6.3                5.0               1.9\n",
       "147                6.5                5.2               2.0\n",
       "148                6.2                5.4               2.3\n",
       "149                5.9                5.1               1.8\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xframe = frame[[\"sepal length (cm)\",\"petal length (cm)\",\"petal width (cm)\"]]\n",
    "xframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.1, 1.4, 0.2],\n",
       " [4.9, 1.4, 0.2],\n",
       " [4.7, 1.3, 0.2],\n",
       " [4.6, 1.5, 0.2],\n",
       " [5.0, 1.4, 0.2],\n",
       " [5.4, 1.7, 0.4],\n",
       " [4.6, 1.4, 0.3],\n",
       " [5.0, 1.5, 0.2],\n",
       " [4.4, 1.4, 0.2],\n",
       " [4.9, 1.5, 0.1],\n",
       " [5.4, 1.5, 0.2],\n",
       " [4.8, 1.6, 0.2],\n",
       " [4.8, 1.4, 0.1],\n",
       " [4.3, 1.1, 0.1],\n",
       " [5.8, 1.2, 0.2],\n",
       " [5.7, 1.5, 0.4],\n",
       " [5.4, 1.3, 0.4],\n",
       " [5.1, 1.4, 0.3],\n",
       " [5.7, 1.7, 0.3],\n",
       " [5.1, 1.5, 0.3],\n",
       " [5.4, 1.7, 0.2],\n",
       " [5.1, 1.5, 0.4],\n",
       " [4.6, 1.0, 0.2],\n",
       " [5.1, 1.7, 0.5],\n",
       " [4.8, 1.9, 0.2],\n",
       " [5.0, 1.6, 0.2],\n",
       " [5.0, 1.6, 0.4],\n",
       " [5.2, 1.5, 0.2],\n",
       " [5.2, 1.4, 0.2],\n",
       " [4.7, 1.6, 0.2],\n",
       " [4.8, 1.6, 0.2],\n",
       " [5.4, 1.5, 0.4],\n",
       " [5.2, 1.5, 0.1],\n",
       " [5.5, 1.4, 0.2],\n",
       " [4.9, 1.5, 0.2],\n",
       " [5.0, 1.2, 0.2],\n",
       " [5.5, 1.3, 0.2],\n",
       " [4.9, 1.4, 0.1],\n",
       " [4.4, 1.3, 0.2],\n",
       " [5.1, 1.5, 0.2],\n",
       " [5.0, 1.3, 0.3],\n",
       " [4.5, 1.3, 0.3],\n",
       " [4.4, 1.3, 0.2],\n",
       " [5.0, 1.6, 0.6],\n",
       " [5.1, 1.9, 0.4],\n",
       " [4.8, 1.4, 0.3],\n",
       " [5.1, 1.6, 0.2],\n",
       " [4.6, 1.4, 0.2],\n",
       " [5.3, 1.5, 0.2],\n",
       " [5.0, 1.4, 0.2],\n",
       " [7.0, 4.7, 1.4],\n",
       " [6.4, 4.5, 1.5],\n",
       " [6.9, 4.9, 1.5],\n",
       " [5.5, 4.0, 1.3],\n",
       " [6.5, 4.6, 1.5],\n",
       " [5.7, 4.5, 1.3],\n",
       " [6.3, 4.7, 1.6],\n",
       " [4.9, 3.3, 1.0],\n",
       " [6.6, 4.6, 1.3],\n",
       " [5.2, 3.9, 1.4],\n",
       " [5.0, 3.5, 1.0],\n",
       " [5.9, 4.2, 1.5],\n",
       " [6.0, 4.0, 1.0],\n",
       " [6.1, 4.7, 1.4],\n",
       " [5.6, 3.6, 1.3],\n",
       " [6.7, 4.4, 1.4],\n",
       " [5.6, 4.5, 1.5],\n",
       " [5.8, 4.1, 1.0],\n",
       " [6.2, 4.5, 1.5],\n",
       " [5.6, 3.9, 1.1],\n",
       " [5.9, 4.8, 1.8],\n",
       " [6.1, 4.0, 1.3],\n",
       " [6.3, 4.9, 1.5],\n",
       " [6.1, 4.7, 1.2],\n",
       " [6.4, 4.3, 1.3],\n",
       " [6.6, 4.4, 1.4],\n",
       " [6.8, 4.8, 1.4],\n",
       " [6.7, 5.0, 1.7],\n",
       " [6.0, 4.5, 1.5],\n",
       " [5.7, 3.5, 1.0],\n",
       " [5.5, 3.8, 1.1],\n",
       " [5.5, 3.7, 1.0],\n",
       " [5.8, 3.9, 1.2],\n",
       " [6.0, 5.1, 1.6],\n",
       " [5.4, 4.5, 1.5],\n",
       " [6.0, 4.5, 1.6],\n",
       " [6.7, 4.7, 1.5],\n",
       " [6.3, 4.4, 1.3],\n",
       " [5.6, 4.1, 1.3],\n",
       " [5.5, 4.0, 1.3],\n",
       " [5.5, 4.4, 1.2],\n",
       " [6.1, 4.6, 1.4],\n",
       " [5.8, 4.0, 1.2],\n",
       " [5.0, 3.3, 1.0],\n",
       " [5.6, 4.2, 1.3],\n",
       " [5.7, 4.2, 1.2],\n",
       " [5.7, 4.2, 1.3],\n",
       " [6.2, 4.3, 1.3],\n",
       " [5.1, 3.0, 1.1],\n",
       " [5.7, 4.1, 1.3],\n",
       " [6.3, 6.0, 2.5],\n",
       " [5.8, 5.1, 1.9],\n",
       " [7.1, 5.9, 2.1],\n",
       " [6.3, 5.6, 1.8],\n",
       " [6.5, 5.8, 2.2],\n",
       " [7.6, 6.6, 2.1],\n",
       " [4.9, 4.5, 1.7],\n",
       " [7.3, 6.3, 1.8],\n",
       " [6.7, 5.8, 1.8],\n",
       " [7.2, 6.1, 2.5],\n",
       " [6.5, 5.1, 2.0],\n",
       " [6.4, 5.3, 1.9],\n",
       " [6.8, 5.5, 2.1],\n",
       " [5.7, 5.0, 2.0],\n",
       " [5.8, 5.1, 2.4],\n",
       " [6.4, 5.3, 2.3],\n",
       " [6.5, 5.5, 1.8],\n",
       " [7.7, 6.7, 2.2],\n",
       " [7.7, 6.9, 2.3],\n",
       " [6.0, 5.0, 1.5],\n",
       " [6.9, 5.7, 2.3],\n",
       " [5.6, 4.9, 2.0],\n",
       " [7.7, 6.7, 2.0],\n",
       " [6.3, 4.9, 1.8],\n",
       " [6.7, 5.7, 2.1],\n",
       " [7.2, 6.0, 1.8],\n",
       " [6.2, 4.8, 1.8],\n",
       " [6.1, 4.9, 1.8],\n",
       " [6.4, 5.6, 2.1],\n",
       " [7.2, 5.8, 1.6],\n",
       " [7.4, 6.1, 1.9],\n",
       " [7.9, 6.4, 2.0],\n",
       " [6.4, 5.6, 2.2],\n",
       " [6.3, 5.1, 1.5],\n",
       " [6.1, 5.6, 1.4],\n",
       " [7.7, 6.1, 2.3],\n",
       " [6.3, 5.6, 2.4],\n",
       " [6.4, 5.5, 1.8],\n",
       " [6.0, 4.8, 1.8],\n",
       " [6.9, 5.4, 2.1],\n",
       " [6.7, 5.6, 2.4],\n",
       " [6.9, 5.1, 2.3],\n",
       " [5.8, 5.1, 1.9],\n",
       " [6.8, 5.9, 2.3],\n",
       " [6.7, 5.7, 2.5],\n",
       " [6.7, 5.2, 2.3],\n",
       " [6.3, 5.0, 1.9],\n",
       " [6.5, 5.2, 2.0],\n",
       " [6.2, 5.4, 2.3],\n",
       " [5.9, 5.1, 1.8]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = xframe.values.tolist()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "145    2\n",
       "146    2\n",
       "147    2\n",
       "148    2\n",
       "149    2\n",
       "Name: target, Length: 150, dtype: int32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yframe = frame[\"target\"]\n",
    "yframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1  2\n",
       "0    1  0  0\n",
       "1    1  0  0\n",
       "2    1  0  0\n",
       "3    1  0  0\n",
       "4    1  0  0\n",
       "..  .. .. ..\n",
       "145  0  0  1\n",
       "146  0  0  1\n",
       "147  0  0  1\n",
       "148  0  0  1\n",
       "149  0  0  1\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydummies = pandas.get_dummies(frame[\"target\"])\n",
    "ydummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = ydummies.values.tolist()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De data is nu opgesteld, nu moeten we ons model opstellen en trainen. We hebben te maken met 3 features, dus 3 inputs. De eerste layer heeft dus 3 neurons (hoeft niet gedefinieerd te worden in ons netwerk).\\\n",
    "\\\n",
    "De tweede layer zullen we uit een varierend aantal neurons opbouwen om te testen waar de accuracy het beste is.\\\n",
    "\\\n",
    "De derde layer zal drie neurons hebben; deze staat gelijk aan het aantal mogelijke classificaties. De neuron\n",
    "met de hoogste waarde in deze layer toont aan welke classificatie het netwerk geeft aan een gegeven set features.\\\n",
    "\\\n",
    "Voor elke neuron geven we random weights mee om mee te beginnen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pas op: onderstaande cel duurt heel lang om te runnen bij een hoog aantal epochs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network took 9.512921571731567 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Definitions\n",
    "inputs = len(xframe.columns)  # Aantal features\n",
    "outputs = len(yframe.unique())  # Aantal outputs\n",
    "neurons = 3  # Aantal neurons in de eerste layer.\n",
    "eta = 0.1  # Learning rate\n",
    "epochs = 40  # Aantal keer dat het netwerk door de **hele** trainset heen loopt\n",
    "errortolerance = 0.01  # Als de MSE onder deze grens ligt, dan houdt het netwerk op met trainen\n",
    "# End of definitions\n",
    "start = time.time()\n",
    "l1 = NeuronLayer([])\n",
    "l2 = NeuronLayer([])\n",
    "\n",
    "for i in range(neurons):  # Tweede layer\n",
    "    n = Neuron([random.random() for i in range(inputs)],Sigmoid().activate)\n",
    "    l1.neurons.append(n)\n",
    "    \n",
    "for j in range(outputs):  # Output layer\n",
    "    n = Neuron([random.random() for i in range(neurons)],Sigmoid().activate)\n",
    "    l2.neurons.append(n)\n",
    "\n",
    "ntwrk = NeuronNetwork([l1,l2],learningrate=eta)\n",
    "ntwrk.train(list(x_train),list(y_train),epochs=epochs,errortreshold=errortolerance)\n",
    "end = time.time()\n",
    "print(\"Training network took {} seconds.\".format((end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy network:\n",
      "0.631578947368421\n",
      "Error network (RMSE) (trainset):\n",
      "0.5856579236367815\n",
      "Error network (RMSE) (testset):\n",
      "0.6049563694087015\n"
     ]
    }
   ],
   "source": [
    "# score = accuracy_score(ntwrk.feed_forward([x for x in x_test]),y_test)\n",
    "# y_pred = [ntwrk.feed_forward(x) for x in x_test]\n",
    "# accuracy_score(y_pred,y_test)\n",
    "y_pred = [ntwrk.feed_forward(x) for x in x_test]\n",
    "indexes_y_pred = [y_pred[i].index(max(y_pred[i])) for i in range(len(y_pred))]\n",
    "indexes_y_true = [y_test[i].index(max(y_test[i])) for i in range(len(y_test))]\n",
    "print(\"Accuracy network:\")\n",
    "print(accuracy_score(indexes_y_pred,indexes_y_true))\n",
    "print(\"Error network (RMSE) (trainset):\")\n",
    "print(np.sqrt(ntwrk.error(list(x_train),list(y_train))))\n",
    "print(\"Error network (RMSE) (testset):\")\n",
    "print(np.sqrt(ntwrk.error(list(x_test),list(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
